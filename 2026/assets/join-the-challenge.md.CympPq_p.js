import{_ as a,c as i,o as n,ah as r}from"./chunks/framework.CthHURaL.js";const g=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"join-the-challenge.md","filePath":"join-the-challenge.md"}'),o={name:"join-the-challenge.md"};function t(l,e,c,s,d,m){return n(),i("div",null,[...e[0]||(e[0]=[r('<h2 id="join-the-challenge" tabindex="-1">Join the challenge <a class="header-anchor" href="#join-the-challenge" aria-label="Permalink to “Join the challenge”">​</a></h2><ol><li>Sign up and apply to join the challenge on the website.</li><li>Submit your team information.</li></ol><h2 id="download-the-data" tabindex="-1">Download the data <a class="header-anchor" href="#download-the-data" aria-label="Permalink to “Download the data”">​</a></h2><p>Download data here.</p><h2 id="train-the-model" tabindex="-1">Train the model <a class="header-anchor" href="#train-the-model" aria-label="Permalink to “Train the model”">​</a></h2><p>Participants are expected to train models in their local computational environments and to submit docker containers on Synapse platform. A leaderboard will be maintained on the Synapse platform during the validation phase.</p><h2 id="code-availability" tabindex="-1">Code availability <a class="header-anchor" href="#code-availability" aria-label="Permalink to “Code availability”">​</a></h2><p>We provide the code to facilitate the use of the data we release at . A brief description of the provided package is as follows:</p><ul><li>CMRxReconDemo: contains parallel imaging reconstruction code</li><li>ChallengeDataFormat: explains the challenge data and the rules for data submission</li><li>CMRxReconMaskGeneration: contains code for varied undersampling mask generation in different tasks</li><li>Evaluation: contains image quality evaluation code for validation and testing</li><li>Submission: contains the structure for challenge submission</li></ul><h2 id="evaluation-platform" tabindex="-1">Evaluation platform <a class="header-anchor" href="#evaluation-platform" aria-label="Permalink to “Evaluation platform”">​</a></h2><p>Validation of the received docker on unseen test set will be performed on a cloud server with a configuration as follows:</p><ul><li>OS: Linux (RockyOS 9)</li><li>CPU: 2.0GHz, 112 cores</li><li>RAM: 64 GB</li><li>GPU: A6000 (48 GB VRAM, single GPU)</li><li>GPU Driver Version: 550</li><li>CUDA Version: 12.4</li><li>Time Limitation: 40 hours/team for each task.</li></ul><h2 id="publication-references" tabindex="-1">Publication references <a class="header-anchor" href="#publication-references" aria-label="Permalink to “Publication references”">​</a></h2><p>You are free to use and/or refer to the CMRxRecon2025 challenge and datasets in your own research after the embargo period (Dec. 2025), provided that you cite the following manuscripts:</p><h3 id="reference-of-the-cmr-imaging-acquisition-protocol" tabindex="-1">Reference of the CMR imaging acquisition protocol <a class="header-anchor" href="#reference-of-the-cmr-imaging-acquisition-protocol" aria-label="Permalink to “Reference of the CMR imaging acquisition protocol”">​</a></h3><ol><li>Wang C, Lyu J, Wang S, et al. CMRxRecon: A publicly available k-space dataset and benchmark to advance deep learning for cardiac MRI. <em>Scientific Data</em>. 2024;11(1):687.</li><li>Wang Z, Wang F, Qin C, et al. CMRxRecon2024: A Multimodality, Multiview k-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI. <em>Radiology: Artificial Intelligence</em>. 2025;7(2):e240443. doi:<a href="https://pubs.rsna.org/doi/10.1148/ryai.240443" target="_blank" rel="noreferrer">10.1148/ryai.240443</a></li><li>Lyu J, Qin C, Wang S, et al. The state-of-the-art in cardiac MRI reconstruction: Results of the CMRxRecon challenge in MICCAI 2023. <em>Medical Image Analysis</em>. 2025;101:103485. doi:<a href="https://doi.org/10.1016/j.media.2025.103485" target="_blank" rel="noreferrer">10.1016/j.media.2025.103485</a></li><li>Wang C, Li Y, Lv J, et al. Recommendation for Cardiac Magnetic Resonance Imaging-Based Phenotypic Study: Imaging Part. <em>Phenomics</em>. 2021;1(4):151-170.</li><li>Wang S, Qin C, Wang C, et al. The Extreme Cardiac MRI Analysis Challenge under Respiratory Motion (CMRxMotion). arXiv preprint <a href="https://arxiv.org/abs/2210.06385" target="_blank" rel="noreferrer">arXiv:2210.06385</a>. 2022.</li></ol><h3 id="reference-for-previously-developed-reconstruction-algorithms" tabindex="-1">Reference for previously developed reconstruction algorithms <a class="header-anchor" href="#reference-for-previously-developed-reconstruction-algorithms" aria-label="Permalink to “Reference for previously developed reconstruction algorithms”">​</a></h3><ol><li>Wang C, Jang J, Neisius U, et al. Black blood myocardial T2 mapping. <em>Magnetic Resonance in Medicine</em>. 2019;81(1):153-166.</li><li>Lyu J, Wang S, Tian Y, et al. STADNet: Spatial-Temporal Attention-Guided Dual-Path Network for cardiac cine MRI super-resolution. <em>Medical Image Analysis</em>. 2024;94:103142.</li><li>Lyu J, Li G, Wang C, et al. Region-focused multi-view transformer-based generative adversarial network for cardiac cine MRI reconstruction. <em>Medical Image Analysis</em>. 2023;102760.</li><li>Lyu J, Tian Y, Cai Q, Wang C, Qin J. Adaptive channel-modulated personalized federated learning for magnetic resonance image reconstruction. <em>Computers in Biology and Medicine</em>. 2023;165:107330.</li><li>Qin C, Schlemper J, Caballero J, et al. Convolutional recurrent neural networks for dynamic MR image reconstruction. <em>IEEE Transactions on Medical Imaging</em>. 2018;38(1):280-290.</li><li>Qin C, Duan J, Hammernik K, et al. Complementary time-frequency domain networks for dynamic parallel MR image reconstruction. <em>Magnetic Resonance in Medicine</em>. 2021;86(6):3274-3291.</li><li>Lyu J, Tian Y, Cai Q, et al. Adaptive channel-modulated personalized federated learning for magnetic resonance image reconstruction. <em>Computers in Biology and Medicine</em>. 2023;165:107330.</li><li>Lyu J, Tong X, Wang C. Parallel Imaging With a Combination of SENSE and Generative Adversarial Networks (GAN). <em>Quantitative Imaging in Medicine and Surgery</em>. 2020;10(12):2260-2273.</li><li>Lyu J, Sui B, Wang C, et al. DuDoCAF: Dual-Domain Cross-Attention Fusion with Recurrent Transformer for Fast Multi-contrast MR Imaging. In: <em>International Conference on Medical Image Computing and Computer-Assisted Intervention</em>. Springer; 2022:474-484.</li><li>Ouyang C, Schlemper K, et al. Generalizing Deep Learning MRI Reconstruction across Different Domains, arXiv preprint arXiv: 1902.10815, 2019.</li><li>Wang Z, Qian C, Guo D, Sun H, Li R, Zhao B, Qu X, One-dimensional Deep Low-rank and Sparse Network for Accelerated MRI, IEEE Transactions on Medical Imaging, 42: 79-90, 2023. <a href="https://doi.org/10.1109/TMI.2022.3203312" target="_blank" rel="noreferrer">https://doi.org/10.1109/TMI.2022.3203312</a></li><li>Wang Z, et al., Deep Separable Spatiotemporal Learning for Fast Dynamic Cardiac MRI, arXiv preprint arXiv:2402.15939, 2024. <a href="https://arxiv.org/abs/2402.15939" target="_blank" rel="noreferrer">https://arxiv.org/abs/2402.15939</a></li></ol>',18)])])}const u=a(o,[["render",t]]);export{g as __pageData,u as default};
