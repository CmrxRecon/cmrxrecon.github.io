<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>CMRxRecon2026</title>
    <meta name="description" content="website for CMRxRecon series competitions">
    <meta name="generator" content="VitePress v2.0.0-alpha.15">
    <link rel="preload stylesheet" href="/2026/assets/style.D1-eCG83.css" as="style">
    <link rel="preload stylesheet" href="/2026/vp-icons.css" as="style">
    
    <script type="module" src="/2026/assets/app.C4tDhH4c.js"></script>
    <link rel="preload" href="/2026/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/2026/assets/chunks/theme.ccAqa6sr.js">
    <link rel="modulepreload" href="/2026/assets/chunks/framework.CthHURaL.js">
    <link rel="modulepreload" href="/2026/assets/join-the-challenge.md.CympPq_p.lean.js">
    <link rel="icon" type="image/png" href="/2026/home/face.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-aa5637b3><!--[--><!--]--><!--[--><span tabindex="-1" data-v-f023c09b></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-f023c09b>Skip to content</a><!--]--><!----><header class="VPNav" data-v-aa5637b3 data-v-5b7fda00><div class="VPNavBar" data-v-5b7fda00 data-v-787d5905><div class="wrapper" data-v-787d5905><div class="container" data-v-787d5905><div class="title" data-v-787d5905><div class="VPNavBarTitle" data-v-787d5905 data-v-016ef833><a class="title" href="/2026/" data-v-016ef833><!--[--><!--]--><!--[--><img class="VPImage logo" src="/2026/logo-combine.png" alt data-v-2aac4770><!--]--><span data-v-016ef833>CMRxRecon2026</span><!--[--><!--]--></a></div></div><div class="content" data-v-787d5905><div class="content-body" data-v-787d5905><!--[--><!--]--><div class="VPNavBarSearch search" data-v-787d5905><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-787d5905 data-v-8fa2167c><span id="main-nav-aria-label" class="visually-hidden" data-v-8fa2167c> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/2026/" tabindex="0" data-v-8fa2167c data-v-691eb544><!--[--><span data-v-691eb544>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/2026/data.html" tabindex="0" data-v-8fa2167c data-v-691eb544><!--[--><span data-v-691eb544>Data</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/2026/tasks.html" tabindex="0" data-v-8fa2167c data-v-691eb544><!--[--><span data-v-691eb544>Tasks</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink active" href="/2026/join-the-challenge.html" tabindex="0" data-v-8fa2167c data-v-691eb544><!--[--><span data-v-691eb544>Join the challenge</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-8fa2167c data-v-53e4ba04><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-53e4ba04><span class="text" data-v-53e4ba04><!----><span data-v-53e4ba04>Submission</span><span class="vpi-chevron-down text-icon" data-v-53e4ba04></span></span></button><div class="menu" data-v-53e4ba04><div class="VPMenu" data-v-53e4ba04 data-v-a919ad15><div class="items" data-v-a919ad15><!--[--><!--[--><div class="VPMenuLink" data-v-a919ad15 data-v-24a2cfbc><a class="VPLink link" href="/2026/submission-task.html" data-v-24a2cfbc><!--[--><span data-v-24a2cfbc>Task Submission</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-a919ad15 data-v-24a2cfbc><a class="VPLink link" href="/2026/submission-stacom-workshop-paper.html" data-v-24a2cfbc><!--[--><span data-v-24a2cfbc>Stacom workshop paper</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/2026/sponsors.html" tabindex="0" data-v-8fa2167c data-v-691eb544><!--[--><span data-v-691eb544>Sponsors</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/2026/faq.html" tabindex="0" data-v-8fa2167c data-v-691eb544><!--[--><span data-v-691eb544>FAQ</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-787d5905 data-v-fb50fb6d><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-fb50fb6d data-v-3ab2dbd5 data-v-1103351a><span class="check" data-v-1103351a><span class="icon" data-v-1103351a><!--[--><span class="vpi-sun sun" data-v-3ab2dbd5></span><span class="vpi-moon moon" data-v-3ab2dbd5></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-787d5905 data-v-abca0262 data-v-c4aadf9f><!--[--><a class="VPSocialLink no-icon" href="https://github.com/CmrxRecon" aria-label="github" target="_blank" rel="me noopener" data-v-c4aadf9f data-v-2098176d><span class="vpi-social-github"></span></a><a class="VPSocialLink no-icon" href="https://twitter.com/CMRxRecon" aria-label="twitter" target="_blank" rel="me noopener" data-v-c4aadf9f data-v-2098176d><span class="vpi-social-twitter"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-787d5905 data-v-df5658be data-v-53e4ba04><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-53e4ba04><span class="vpi-more-horizontal icon" data-v-53e4ba04></span></button><div class="menu" data-v-53e4ba04><div class="VPMenu" data-v-53e4ba04 data-v-a919ad15><!----><!--[--><!--[--><!----><div class="group" data-v-df5658be><div class="item appearance" data-v-df5658be><p class="label" data-v-df5658be>Appearance</p><div class="appearance-action" data-v-df5658be><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-df5658be data-v-3ab2dbd5 data-v-1103351a><span class="check" data-v-1103351a><span class="icon" data-v-1103351a><!--[--><span class="vpi-sun sun" data-v-3ab2dbd5></span><span class="vpi-moon moon" data-v-3ab2dbd5></span><!--]--></span></span></button></div></div></div><div class="group" data-v-df5658be><div class="item social-links" data-v-df5658be><div class="VPSocialLinks social-links-list" data-v-df5658be data-v-c4aadf9f><!--[--><a class="VPSocialLink no-icon" href="https://github.com/CmrxRecon" aria-label="github" target="_blank" rel="me noopener" data-v-c4aadf9f data-v-2098176d><span class="vpi-social-github"></span></a><a class="VPSocialLink no-icon" href="https://twitter.com/CMRxRecon" aria-label="twitter" target="_blank" rel="me noopener" data-v-c4aadf9f data-v-2098176d><span class="vpi-social-twitter"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-787d5905 data-v-95e8efd7><span class="container" data-v-95e8efd7><span class="top" data-v-95e8efd7></span><span class="middle" data-v-95e8efd7></span><span class="bottom" data-v-95e8efd7></span></span></button></div></div></div></div><div class="divider" data-v-787d5905><div class="divider-line" data-v-787d5905></div></div></div><!----></header><div class="VPLocalNav empty fixed" data-v-aa5637b3 data-v-cba36b6a><div class="container" data-v-cba36b6a><!----><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-cba36b6a data-v-5284fa83><button data-v-5284fa83>Return to top</button><!----></div></div></div><!----><div class="VPContent" id="VPContent" data-v-aa5637b3 data-v-e2017ced><div class="VPDoc has-aside" data-v-e2017ced data-v-5137736c><!--[--><!--]--><div class="container" data-v-5137736c><div class="aside" data-v-5137736c><div class="aside-curtain" data-v-5137736c></div><div class="aside-container" data-v-5137736c><div class="aside-content" data-v-5137736c><div class="VPDocAside" data-v-5137736c data-v-5de03f5c><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-5de03f5c data-v-5889524e><div class="content" data-v-5889524e><div class="outline-marker" data-v-5889524e></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-5889524e>On this page</div><ul class="VPDocOutlineItem root" data-v-5889524e data-v-9d53e7a0><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-5de03f5c></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-5137736c><div class="content-container" data-v-5137736c><!--[--><!--]--><main class="main" data-v-5137736c><div style="position:relative;" class="vp-doc _2026_join-the-challenge" data-v-5137736c><div><h2 id="join-the-challenge" tabindex="-1">Join the challenge <a class="header-anchor" href="#join-the-challenge" aria-label="Permalink to “Join the challenge”">​</a></h2><ol><li>Sign up and apply to join the challenge on the website.</li><li>Submit your team information.</li></ol><h2 id="download-the-data" tabindex="-1">Download the data <a class="header-anchor" href="#download-the-data" aria-label="Permalink to “Download the data”">​</a></h2><p>Download data here.</p><h2 id="train-the-model" tabindex="-1">Train the model <a class="header-anchor" href="#train-the-model" aria-label="Permalink to “Train the model”">​</a></h2><p>Participants are expected to train models in their local computational environments and to submit docker containers on Synapse platform. A leaderboard will be maintained on the Synapse platform during the validation phase.</p><h2 id="code-availability" tabindex="-1">Code availability <a class="header-anchor" href="#code-availability" aria-label="Permalink to “Code availability”">​</a></h2><p>We provide the code to facilitate the use of the data we release at . A brief description of the provided package is as follows:</p><ul><li>CMRxReconDemo: contains parallel imaging reconstruction code</li><li>ChallengeDataFormat: explains the challenge data and the rules for data submission</li><li>CMRxReconMaskGeneration: contains code for varied undersampling mask generation in different tasks</li><li>Evaluation: contains image quality evaluation code for validation and testing</li><li>Submission: contains the structure for challenge submission</li></ul><h2 id="evaluation-platform" tabindex="-1">Evaluation platform <a class="header-anchor" href="#evaluation-platform" aria-label="Permalink to “Evaluation platform”">​</a></h2><p>Validation of the received docker on unseen test set will be performed on a cloud server with a configuration as follows:</p><ul><li>OS: Linux (RockyOS 9)</li><li>CPU: 2.0GHz, 112 cores</li><li>RAM: 64 GB</li><li>GPU: A6000 (48 GB VRAM, single GPU)</li><li>GPU Driver Version: 550</li><li>CUDA Version: 12.4</li><li>Time Limitation: 40 hours/team for each task.</li></ul><h2 id="publication-references" tabindex="-1">Publication references <a class="header-anchor" href="#publication-references" aria-label="Permalink to “Publication references”">​</a></h2><p>You are free to use and/or refer to the CMRxRecon2025 challenge and datasets in your own research after the embargo period (Dec. 2025), provided that you cite the following manuscripts:</p><h3 id="reference-of-the-cmr-imaging-acquisition-protocol" tabindex="-1">Reference of the CMR imaging acquisition protocol <a class="header-anchor" href="#reference-of-the-cmr-imaging-acquisition-protocol" aria-label="Permalink to “Reference of the CMR imaging acquisition protocol”">​</a></h3><ol><li>Wang C, Lyu J, Wang S, et al. CMRxRecon: A publicly available k-space dataset and benchmark to advance deep learning for cardiac MRI. <em>Scientific Data</em>. 2024;11(1):687.</li><li>Wang Z, Wang F, Qin C, et al. CMRxRecon2024: A Multimodality, Multiview k-Space Dataset Boosting Universal Machine Learning for Accelerated Cardiac MRI. <em>Radiology: Artificial Intelligence</em>. 2025;7(2):e240443. doi:<a href="https://pubs.rsna.org/doi/10.1148/ryai.240443" target="_blank" rel="noreferrer">10.1148/ryai.240443</a></li><li>Lyu J, Qin C, Wang S, et al. The state-of-the-art in cardiac MRI reconstruction: Results of the CMRxRecon challenge in MICCAI 2023. <em>Medical Image Analysis</em>. 2025;101:103485. doi:<a href="https://doi.org/10.1016/j.media.2025.103485" target="_blank" rel="noreferrer">10.1016/j.media.2025.103485</a></li><li>Wang C, Li Y, Lv J, et al. Recommendation for Cardiac Magnetic Resonance Imaging-Based Phenotypic Study: Imaging Part. <em>Phenomics</em>. 2021;1(4):151-170.</li><li>Wang S, Qin C, Wang C, et al. The Extreme Cardiac MRI Analysis Challenge under Respiratory Motion (CMRxMotion). arXiv preprint <a href="https://arxiv.org/abs/2210.06385" target="_blank" rel="noreferrer">arXiv:2210.06385</a>. 2022.</li></ol><h3 id="reference-for-previously-developed-reconstruction-algorithms" tabindex="-1">Reference for previously developed reconstruction algorithms <a class="header-anchor" href="#reference-for-previously-developed-reconstruction-algorithms" aria-label="Permalink to “Reference for previously developed reconstruction algorithms”">​</a></h3><ol><li>Wang C, Jang J, Neisius U, et al. Black blood myocardial T2 mapping. <em>Magnetic Resonance in Medicine</em>. 2019;81(1):153-166.</li><li>Lyu J, Wang S, Tian Y, et al. STADNet: Spatial-Temporal Attention-Guided Dual-Path Network for cardiac cine MRI super-resolution. <em>Medical Image Analysis</em>. 2024;94:103142.</li><li>Lyu J, Li G, Wang C, et al. Region-focused multi-view transformer-based generative adversarial network for cardiac cine MRI reconstruction. <em>Medical Image Analysis</em>. 2023;102760.</li><li>Lyu J, Tian Y, Cai Q, Wang C, Qin J. Adaptive channel-modulated personalized federated learning for magnetic resonance image reconstruction. <em>Computers in Biology and Medicine</em>. 2023;165:107330.</li><li>Qin C, Schlemper J, Caballero J, et al. Convolutional recurrent neural networks for dynamic MR image reconstruction. <em>IEEE Transactions on Medical Imaging</em>. 2018;38(1):280-290.</li><li>Qin C, Duan J, Hammernik K, et al. Complementary time-frequency domain networks for dynamic parallel MR image reconstruction. <em>Magnetic Resonance in Medicine</em>. 2021;86(6):3274-3291.</li><li>Lyu J, Tian Y, Cai Q, et al. Adaptive channel-modulated personalized federated learning for magnetic resonance image reconstruction. <em>Computers in Biology and Medicine</em>. 2023;165:107330.</li><li>Lyu J, Tong X, Wang C. Parallel Imaging With a Combination of SENSE and Generative Adversarial Networks (GAN). <em>Quantitative Imaging in Medicine and Surgery</em>. 2020;10(12):2260-2273.</li><li>Lyu J, Sui B, Wang C, et al. DuDoCAF: Dual-Domain Cross-Attention Fusion with Recurrent Transformer for Fast Multi-contrast MR Imaging. In: <em>International Conference on Medical Image Computing and Computer-Assisted Intervention</em>. Springer; 2022:474-484.</li><li>Ouyang C, Schlemper K, et al. Generalizing Deep Learning MRI Reconstruction across Different Domains, arXiv preprint arXiv: 1902.10815, 2019.</li><li>Wang Z, Qian C, Guo D, Sun H, Li R, Zhao B, Qu X, One-dimensional Deep Low-rank and Sparse Network for Accelerated MRI, IEEE Transactions on Medical Imaging, 42: 79-90, 2023. <a href="https://doi.org/10.1109/TMI.2022.3203312" target="_blank" rel="noreferrer">https://doi.org/10.1109/TMI.2022.3203312</a></li><li>Wang Z, et al., Deep Separable Spatiotemporal Learning for Fast Dynamic Cardiac MRI, arXiv preprint arXiv:2402.15939, 2024. <a href="https://arxiv.org/abs/2402.15939" target="_blank" rel="noreferrer">https://arxiv.org/abs/2402.15939</a></li></ol></div></div></main><footer class="VPDocFooter" data-v-5137736c data-v-30c9eb43><!--[--><!--]--><!----><!----></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter" data-v-aa5637b3 data-v-aca8c503><div class="container" data-v-aca8c503><!----><p class="copyright" data-v-aca8c503>Copyright © 2025-present CMRxRecon Team</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"api-examples.md\":\"fchzj_HM\",\"data.md\":\"DeAurjIZ\",\"faq.md\":\"GYHVhIzC\",\"index.md\":\"CJitBAzJ\",\"index_.md\":\"BPMh7vm3\",\"join-the-challenge.md\":\"CympPq_p\",\"markdown-examples.md\":\"PA_E7vuU\",\"navigation.md\":\"Dn2Fjd0B\",\"sponsors.md\":\"Bsg_Fl4F\",\"submission-stacom-workshop-paper.md\":\"xeSkICkp\",\"submission-task.md\":\"Bh2PXJl1\",\"tasks.md\":\"qfS0iVLt\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"CMRxRecon2026\",\"description\":\"website for CMRxRecon series competitions\",\"base\":\"/2026/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/logo-combine.png\",\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Data\",\"link\":\"/data\"},{\"text\":\"Tasks\",\"link\":\"/tasks\"},{\"text\":\"Join the challenge\",\"link\":\"/join-the-challenge\"},{\"text\":\"Submission\",\"items\":[{\"text\":\"Task Submission\",\"link\":\"submission-task\"},{\"text\":\"Stacom workshop paper\",\"link\":\"/submission-stacom-workshop-paper\"}]},{\"text\":\"Sponsors\",\"link\":\"/sponsors\"},{\"text\":\"FAQ\",\"link\":\"/faq\"}],\"sidebar\":[],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/CmrxRecon\"},{\"icon\":\"twitter\",\"link\":\"https://twitter.com/CMRxRecon\"}],\"footer\":{\"copyright\":\"Copyright © 2025-present CMRxRecon Team\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false,\"additionalConfig\":{}}");</script>
    
  </body>
</html>